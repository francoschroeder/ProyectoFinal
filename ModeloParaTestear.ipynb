{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path          = \"jena_climate_2009_2016.csv\"\n",
    "predicted_feature = 0 #T (degC)\n",
    "\n",
    "train_perc = .7\n",
    "val_perc   = .2\n",
    "\n",
    "sequence_length = 24\n",
    "offset          = 1\n",
    "sampling_rate   = 6\n",
    "batch_size      = 256\n",
    "\n",
    "learning_rate   = 0.001\n",
    "epochs          = 50\n",
    "loss            = \"mse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path, parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:10:00</th>\n",
       "      <td>-8.02</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:20:00</th>\n",
       "      <td>-8.41</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.4</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:30:00</th>\n",
       "      <td>-8.51</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.9</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:40:00</th>\n",
       "      <td>-8.31</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01 00:50:00</th>\n",
       "      <td>-8.27</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     T (degC)  Tdew (degC)  rh (%)  VPmax (mbar)  \\\n",
       "Date Time                                                          \n",
       "2009-01-01 00:10:00     -8.02        -8.90    93.3          3.33   \n",
       "2009-01-01 00:20:00     -8.41        -9.28    93.4          3.23   \n",
       "2009-01-01 00:30:00     -8.51        -9.31    93.9          3.21   \n",
       "2009-01-01 00:40:00     -8.31        -9.07    94.2          3.26   \n",
       "2009-01-01 00:50:00     -8.27        -9.04    94.1          3.27   \n",
       "\n",
       "                     VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
       "Date Time                                                                     \n",
       "2009-01-01 00:10:00          3.11          0.22       1.94             3.12   \n",
       "2009-01-01 00:20:00          3.02          0.21       1.89             3.03   \n",
       "2009-01-01 00:30:00          3.01          0.20       1.88             3.02   \n",
       "2009-01-01 00:40:00          3.07          0.19       1.92             3.08   \n",
       "2009-01-01 00:50:00          3.08          0.19       1.92             3.09   \n",
       "\n",
       "                     rho (g/m**3)  \n",
       "Date Time                          \n",
       "2009-01-01 00:10:00       1307.75  \n",
       "2009-01-01 00:20:00       1309.80  \n",
       "2009-01-01 00:30:00       1310.24  \n",
       "2009-01-01 00:40:00       1309.19  \n",
       "2009-01-01 00:50:00       1309.00  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(['Tpot (K)', 'p (mbar)','wv (m/s)', 'max. wv (m/s)', 'wd (deg)'],axis = 1)\n",
    "#df = data.drop([\"Tpot (K)\",\n",
    "#                \"Tdew (degC)\",\n",
    "#                \"rh (%)\",\n",
    "#                \"VPact (mbar)\",\n",
    "#                \"H2OC (mmol/mol)\",\n",
    "#                \"max. wv (m/s)\",\n",
    "#                \"wd (deg)\",],axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Add periodic time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_s = df.index\n",
    "timestamp_s = timestamp_s.map(pd.Timestamp.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 24*60*60\n",
    "year = 365.2425 * day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_length = len(df)\n",
    "\n",
    "train_length = int(df_length*train_perc)\n",
    "val_length   = int(df_length*(train_perc+val_perc))\n",
    "\n",
    "train_mean = df.values[:train_length].mean()\n",
    "train_std  = df.values[:train_length].std()\n",
    "\n",
    "df_norm = (df.values - train_mean) / train_std\n",
    "df_norm = pd.DataFrame(df_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Normalize data\n",
    "- Only normalize data based on training data\n",
    "    - Notice you should only normalize the training data - because validation and test data could affect the normalization\n",
    "- Get the mean and standard deviation of the data\n",
    "    - HINT: Use **.mean()** and **.std()** on the dataframe.\n",
    "- Noramlize the data as follows\n",
    "    - **train_df = (train_df - train_mean) / train_std** (assuming naming fits)\n",
    "    - HINT: The transformation of validation and test data is done similarly with **train_mean** and **train_std**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_norm[:train_length-1]\n",
    "val_df   = df_norm[train_length:val_length-1]\n",
    "test_df_norm  = df_norm[val_length:]\n",
    "test_df       = df[val_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Create datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = sequence_length*sampling_rate + offset*sampling_rate\n",
    "end   = train_length + start\n",
    "\n",
    "x_train = train_df\n",
    "y_train = df_norm[[predicted_feature]][start:end]\n",
    "\n",
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train.values,\n",
    "    y_train,\n",
    "    sequence_length = sequence_length,\n",
    "    sampling_rate = sampling_rate,\n",
    "    shuffle=True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = train_length + sequence_length*sampling_rate + offset*sampling_rate\n",
    "end   = val_length + start\n",
    "\n",
    "x_val = val_df\n",
    "y_val = df_norm[[predicted_feature]][start:end]\n",
    "\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val.values,\n",
    "    y_val,\n",
    "    sequence_length = sequence_length,\n",
    "    sampling_rate = sampling_rate,\n",
    "    shuffle=False,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = val_length + sequence_length*sampling_rate + offset*sampling_rate\n",
    "x_end = len(test_df_norm) - sequence_length*sampling_rate - offset*sampling_rate\n",
    "\n",
    "x_test = test_df_norm[:x_end]\n",
    "y_test = df_norm[[predicted_feature]][start:]\n",
    "\n",
    "dataset_test = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_test.values,\n",
    "    y_test,\n",
    "    sequence_length = sequence_length,\n",
    "    sampling_rate = sampling_rate,\n",
    "    shuffle=False,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df, input_width=24, offset=0, predict_column=0):\n",
    "    x = []\n",
    "    y = []\n",
    "    data_x = df.to_numpy()\n",
    "    data_y = df[predict_column].to_numpy()\n",
    "    \n",
    "    for i in range(input_width, len(data_x) - offset):\n",
    "        x.append(data_x[i - input_width:i,:])\n",
    "        y.append(data_y[i + offset])\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x, y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_norm = test_df_norm[5::6]\n",
    "x_norm, y_norm = create_dataset(test_df_norm, input_width = sequence_length, predict_column = predicted_feature)\n",
    "\n",
    "test_df = test_df[5::6]\n",
    "x_real, y_real = create_dataset(pd.DataFrame(test_df.values), input_width = sequence_length, predict_column = predicted_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.31509975 -0.32009653 -0.04545988 -0.29973698 -0.30215778 -0.31956892\n",
      "  -0.30966847 -0.30221986  3.60470299 -0.32317741 -0.31912238 -0.3245818\n",
      "  -0.32028285]\n",
      " [-0.31640326 -0.31925856 -0.03149373 -0.30038874 -0.30178535 -0.32059311\n",
      "  -0.30942018 -0.30181639  3.61004116 -0.32239482 -0.31891268 -0.32458057\n",
      "  -0.32028099]\n",
      " [-0.31612394 -0.31975514 -0.03676983 -0.30026459 -0.3020026  -0.32022068\n",
      "  -0.30957536 -0.30206468  3.60876869 -0.32158462 -0.31891268 -0.3234453\n",
      "  -0.31924864]\n",
      " [-0.31618601 -0.32034482 -0.04018378 -0.30029563 -0.30228193 -0.32000342\n",
      "  -0.30973054 -0.302344    3.60904801 -0.32080203 -0.31912238 -0.32344334\n",
      "  -0.31924759]\n",
      " [-0.31646533 -0.32037585 -0.03863198 -0.30041977 -0.30231296 -0.32012757\n",
      "  -0.30973054 -0.302344    3.60932734 -0.32010038 -0.31952748 -0.32344137\n",
      "  -0.31924655]\n",
      " [-0.31662051 -0.32040689 -0.03770091 -0.30051288 -0.30231296 -0.32018964\n",
      "  -0.30973054 -0.302344    3.60920319 -0.31952748 -0.32010038 -0.32343941\n",
      "  -0.31924551]\n",
      " [-0.31680673 -0.32053103 -0.03739055 -0.30060599 -0.30237503 -0.32022068\n",
      "  -0.30979261 -0.30240607  3.61112742 -0.31912238 -0.32080203 -0.32343744\n",
      "  -0.31924447]\n",
      " [-0.31689983 -0.32087243 -0.03894234 -0.30063702 -0.30253021 -0.32009653\n",
      "  -0.30988572 -0.30256125  3.61239989 -0.31891268 -0.32158462 -0.32343547\n",
      "  -0.31924344]\n",
      " [-0.31724123 -0.32099657 -0.03770091 -0.30082324 -0.30259229 -0.32022068\n",
      "  -0.30991676 -0.30262332  3.61466551 -0.31891268 -0.32239482 -0.3234335\n",
      "  -0.3192424 ]\n",
      " [-0.31755159 -0.32028275 -0.03087301 -0.30094738 -0.30225089 -0.32068621\n",
      "  -0.30973054 -0.30231296  3.61680699 -0.31912238 -0.32317741 -0.32343153\n",
      "  -0.31924137]\n",
      " [-0.31702398 -0.31932063 -0.02776942 -0.3006991  -0.30181639 -0.32087243\n",
      "  -0.30945122 -0.30187846  3.61519312 -0.31952748 -0.32387907 -0.32342956\n",
      "  -0.31924033]\n",
      " [-0.31702398 -0.31919649 -0.02683834 -0.3006991  -0.30175432 -0.3209345\n",
      "  -0.30942018 -0.30181639  3.61615523 -0.32010038 -0.32445196 -0.32342759\n",
      "  -0.3192393 ]\n",
      " [-0.31705501 -0.31904131 -0.02559691 -0.30073013 -0.30166121 -0.32102761\n",
      "  -0.30935811 -0.30175432  3.61677595 -0.32080203 -0.32485706 -0.32342562\n",
      "  -0.31923827]\n",
      " [-0.31724123 -0.31938271 -0.02683834 -0.30082324 -0.30184742 -0.32096554\n",
      "  -0.30948225 -0.3019095   3.61801739 -0.32158462 -0.32506676 -0.32342365\n",
      "  -0.31923724]\n",
      " [-0.31755159 -0.31991032 -0.02807978 -0.30097842 -0.30209571 -0.32087243\n",
      "  -0.3096064  -0.30215778  3.61966229 -0.32239482 -0.32506676 -0.32342167\n",
      "  -0.31923622]\n",
      " [-0.31748952 -0.3200655  -0.02963157 -0.30094738 -0.30215778 -0.32077932\n",
      "  -0.30966847 -0.30221986  3.6182036  -0.32317741 -0.32485706 -0.3234197\n",
      "  -0.31923519]\n",
      " [-0.31770677 -0.32133797 -0.03676983 -0.30104049 -0.30274747 -0.32028275\n",
      "  -0.3100409  -0.30280954  3.61891743 -0.32387907 -0.32445196 -0.32341772\n",
      "  -0.31923417]\n",
      " [-0.31848267 -0.32186558 -0.03521803 -0.30141292 -0.30296472 -0.32043793\n",
      "  -0.31016504 -0.30302679  3.62292106 -0.32445196 -0.32387907 -0.32341575\n",
      "  -0.31923314]\n",
      " [-0.31832749 -0.32220697 -0.03863198 -0.30131981 -0.3031199  -0.32018964\n",
      "  -0.31025815 -0.30318197  3.62341763 -0.32485706 -0.32317741 -0.32341377\n",
      "  -0.31923212]\n",
      " [-0.31888613 -0.32347944 -0.04328737 -0.30159914 -0.30367854 -0.31991032\n",
      "  -0.31063058 -0.30374061  3.62754541 -0.32506676 -0.32239482 -0.32341179\n",
      "  -0.3192311 ]\n",
      " [-0.31901028 -0.32462777 -0.05011526 -0.30166121 -0.30417512 -0.31947581\n",
      "  -0.31094094 -0.30426822  3.63049382 -0.32506676 -0.32158462 -0.32340982\n",
      "  -0.31923008]\n",
      " [-0.31888613 -0.32518642 -0.05446029 -0.30159914 -0.3044234  -0.31916545\n",
      "  -0.31109612 -0.30448548  3.63204561 -0.32485706 -0.32080203 -0.32340784\n",
      "  -0.31922907]\n",
      " [-0.3189482  -0.32484502 -0.05166706 -0.30163017 -0.30426822 -0.31935167\n",
      "  -0.31100301 -0.30436133  3.63418709 -0.32445196 -0.32010038 -0.32340586\n",
      "  -0.31922805]\n",
      " [-0.3192896  -0.32453466 -0.04763239 -0.30178535 -0.30414408 -0.31966203\n",
      "  -0.31090991 -0.30423719  3.63617339 -0.32387907 -0.31952748 -0.32340388\n",
      "  -0.31922704]]\n",
      "[[-0.3192896 ]\n",
      " [-0.31910338]\n",
      " [-0.31888613]\n",
      " ...\n",
      " [-0.32968662]\n",
      " [-0.3358007 ]\n",
      " [-0.33179706]]\n"
     ]
    }
   ],
   "source": [
    "print(x_norm[1])\n",
    "print(y_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Create model\n",
    "- Create the following model\n",
    "    - **model = models.Sequential()**\n",
    "    - **model.add(layers.LSTM(32, return_sequences=True, input_shape=train_ds[0].shape[1:]))**\n",
    "    - **model.add(layers.Dense(units=1))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset_train.take(1):\n",
    "    x, y = batch\n",
    "    \n",
    "input_shape = x.shape[1], x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 24, 13)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                5888      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,921\n",
      "Trainable params: 5,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(input_shape)\n",
    "#lstm_layer = keras.layers.LSTM(32, return_sequences=True)(inputs)\n",
    "lstm_layer2 = keras.layers.LSTM(32)(inputs)\n",
    "output = keras.layers.Dense(1)(lstm_layer2)\n",
    "\n",
    "model = keras.Model(inputs, output)\n",
    "model.compile(keras.optimizers.Adam(learning_rate), loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Train model\n",
    "- Compile and fit the model\n",
    "- Complie the model as follows\n",
    "    - **model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])**\n",
    "- Fit the model as follows\n",
    "    - **model.fit(x=train_ds[0], y=train_ds[1], validation_data=(val_ds[0], val_ds[1]), epochs=5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1150/1150 [==============================] - 20s 16ms/step - loss: 4.5230e-04 - val_loss: 5.5515e-05\n",
      "Epoch 2/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 4.3988e-05 - val_loss: 2.8803e-05\n",
      "Epoch 3/50\n",
      "1150/1150 [==============================] - 19s 16ms/step - loss: 2.8821e-05 - val_loss: 2.4517e-05\n",
      "Epoch 4/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 2.7694e-05 - val_loss: 4.9964e-05\n",
      "Epoch 5/50\n",
      "1150/1150 [==============================] - 18s 15ms/step - loss: 2.5365e-05 - val_loss: 1.8823e-05\n",
      "Epoch 6/50\n",
      "1150/1150 [==============================] - 18s 15ms/step - loss: 2.4134e-05 - val_loss: 1.8696e-05\n",
      "Epoch 7/50\n",
      "1150/1150 [==============================] - 19s 17ms/step - loss: 2.1202e-05 - val_loss: 1.6262e-05\n",
      "Epoch 8/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 2.0785e-05 - val_loss: 2.5142e-05\n",
      "Epoch 9/50\n",
      "1150/1150 [==============================] - 19s 16ms/step - loss: 1.9117e-05 - val_loss: 2.2421e-05\n",
      "Epoch 10/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 1.8679e-05 - val_loss: 2.3331e-05\n",
      "Epoch 11/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 1.8370e-05 - val_loss: 1.5909e-05\n",
      "Epoch 12/50\n",
      "1150/1150 [==============================] - 19s 16ms/step - loss: 1.7358e-05 - val_loss: 1.4797e-05\n",
      "Epoch 13/50\n",
      "1150/1150 [==============================] - 19s 17ms/step - loss: 1.7217e-05 - val_loss: 1.3766e-05\n",
      "Epoch 14/50\n",
      "1150/1150 [==============================] - 19s 16ms/step - loss: 1.6897e-05 - val_loss: 2.4035e-05\n",
      "Epoch 15/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 1.6273e-05 - val_loss: 2.4520e-05\n",
      "Epoch 16/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 1.6143e-05 - val_loss: 1.4216e-05\n",
      "Epoch 17/50\n",
      "1150/1150 [==============================] - 18s 15ms/step - loss: 1.5751e-05 - val_loss: 1.6244e-05\n",
      "Epoch 18/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 1.5563e-05 - val_loss: 3.4267e-05\n",
      "Epoch 19/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 1.5163e-05 - val_loss: 1.4879e-05\n",
      "Epoch 20/50\n",
      "1150/1150 [==============================] - 18s 16ms/step - loss: 1.5086e-05 - val_loss: 1.5375e-05\n",
      "Epoch 21/50\n",
      "1150/1150 [==============================] - 17s 15ms/step - loss: 1.5081e-05 - val_loss: 1.4011e-05\n",
      "Epoch 22/50\n",
      "1150/1150 [==============================] - 17s 15ms/step - loss: 1.4743e-05 - val_loss: 1.3008e-05\n",
      "Epoch 23/50\n",
      "1150/1150 [==============================] - 17s 15ms/step - loss: 1.4339e-05 - val_loss: 2.0941e-05\n",
      "Epoch 24/50\n",
      "1146/1150 [============================>.] - ETA: 0s - loss: 1.4342e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13024/2211364861.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\proyecto-final\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\proyecto-final\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1494\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1495\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1496\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\proyecto-final\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\proyecto-final\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[1;32m~\\miniconda3\\envs\\proyecto-final\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\proyecto-final\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 719\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\proyecto-final\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3119\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3120\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3121\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_train, epochs = epochs, validation_data=dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Predict data\n",
    "- Apply the model on the test data\n",
    "    - HINT: Use **model.predict(x)**, where **x** is assigned to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_norm)\n",
    "y_pred = y_pred * train_std + train_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Plot the result\n",
    "- Plot a window of the data predicted together with the actual data.\n",
    "- One way:\n",
    "    - **fig, ax = plt.subplots()**\n",
    "    - **ax.plot(y[i:i+96*2,0], c='g')**\n",
    "    - **ax.plot(pred[i:i+96*2,-1,0], c='r')**\n",
    "- It will plot a window of 96 hours, where you can index with **i** (**i=150** as an example) and **y** is the real values and **pred** are the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(y_real[0:100], c='g', label=\"Test Data\")\n",
    "ax.plot(y_pred[0:100], c='r', label=\"Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(y_real[500:600], c='g', label=\"Test Data\")\n",
    "ax.plot(y_pred[500:600], c='r', label=\"Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(y_real[200:300], c='g', label=\"Test Data\")\n",
    "ax.plot(y_pred[200:300], c='r', label=\"Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(y_real[950:1050], c='g', label=\"Test Data\")\n",
    "ax.plot(y_pred[950:1050], c='r', label=\"Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(y_real[1000:1100], c='g', label=\"Test Data\")\n",
    "ax.plot(y_pred[1000:1100], c='r', label=\"Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "for x, y in dataset_test.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        12,\n",
    "        \"Single Step Prediction\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

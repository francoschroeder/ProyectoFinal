{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path          = \"jena_climate_2009_2016.csv\"\n",
    "predicted_feature = 'T (degC)'\n",
    "dropped_features  = ['Tpot (K)', 'p (mbar)','wv (m/s)', 'max. wv (m/s)', 'wd (deg)', 'Day cos', 'Year sin']\n",
    "\n",
    "\n",
    "train_perc = .7\n",
    "val_perc   = .2\n",
    "\n",
    "sequence_length = 24\n",
    "offset          = 3\n",
    "sampling_rate   = 6\n",
    "batch_size      = 256\n",
    "\n",
    "learning_rate   = 0.0009\n",
    "epochs          = 10\n",
    "loss            = \"mse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(csv_path, parse_dates=True, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Add periodic time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_s = data.index\n",
    "timestamp_s = timestamp_s.map(pd.Timestamp.timestamp)\n",
    "\n",
    "day = 24*60*60\n",
    "year = 365.2425 * day\n",
    "\n",
    "data['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "data['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "data['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "data['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(dropped_features, axis = 1)\n",
    "\n",
    "predicted_feature = df.columns.get_loc(predicted_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_length = len(df)\n",
    "\n",
    "train_length = int(df_length*train_perc)\n",
    "val_length   = int(df_length*(train_perc+val_perc))\n",
    "\n",
    "train_mean = df.values[:train_length].mean(axis=0)\n",
    "train_std  = df.values[:train_length].std(axis=0)\n",
    "\n",
    "df_norm = (df.values - train_mean) / train_std\n",
    "df_norm = pd.DataFrame(df_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Normalize data\n",
    "- Only normalize data based on training data\n",
    "    - Notice you should only normalize the training data - because validation and test data could affect the normalization\n",
    "- Get the mean and standard deviation of the data\n",
    "    - HINT: Use **.mean()** and **.std()** on the dataframe.\n",
    "- Noramlize the data as follows\n",
    "    - **train_df = (train_df - train_mean) / train_std** (assuming naming fits)\n",
    "    - HINT: The transformation of validation and test data is done similarly with **train_mean** and **train_std**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_norm[:train_length-1]\n",
    "val_df   = df_norm[train_length:val_length-1]\n",
    "test_df_norm  = df_norm[val_length:]\n",
    "test_df       = df[val_length:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Create datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = sequence_length*sampling_rate + offset*sampling_rate\n",
    "end   = train_length + start\n",
    "\n",
    "x_train = train_df\n",
    "y_train = df_norm[[predicted_feature]][start:end]\n",
    "\n",
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train.values,\n",
    "    y_train,\n",
    "    sequence_length = sequence_length,\n",
    "    sampling_rate = sampling_rate,\n",
    "    shuffle=True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = train_length + sequence_length*sampling_rate + offset*sampling_rate\n",
    "end   = val_length + start\n",
    "\n",
    "x_val = val_df\n",
    "y_val = df_norm[[predicted_feature]][start:end]\n",
    "\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val.values,\n",
    "    y_val,\n",
    "    sequence_length = sequence_length,\n",
    "    sampling_rate = sampling_rate,\n",
    "    shuffle=False,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = val_length + sequence_length*sampling_rate + offset*sampling_rate\n",
    "x_end = len(test_df_norm) - sequence_length*sampling_rate - offset*sampling_rate\n",
    "\n",
    "x_test = test_df_norm[:x_end]\n",
    "y_test = df_norm[[predicted_feature]][start:]\n",
    "\n",
    "dataset_test = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_test.values,\n",
    "    y_test,\n",
    "    sequence_length = sequence_length,\n",
    "    sequence_stride = sampling_rate,\n",
    "    sampling_rate = sampling_rate,\n",
    "    shuffle=False,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Create model\n",
    "- Create the following model\n",
    "    - **model = models.Sequential()**\n",
    "    - **model.add(layers.LSTM(32, return_sequences=True, input_shape=train_ds[0].shape[1:]))**\n",
    "    - **model.add(layers.Dense(units=1))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset_train.take(1):\n",
    "    x, y = batch\n",
    "    \n",
    "input_shape = x.shape[1], x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 24, 11)]          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 24, 32)            5632      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 13,985\n",
      "Trainable params: 13,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(input_shape)\n",
    "lstm_layer = keras.layers.LSTM(32, return_sequences=True)(inputs)\n",
    "lstm_layer2 = keras.layers.LSTM(32)(lstm_layer)\n",
    "output = keras.layers.Dense(1)(lstm_layer2)\n",
    "\n",
    "model = keras.Model(inputs, output)\n",
    "model.compile(keras.optimizers.Adam(learning_rate), loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Train model\n",
    "- Compile and fit the model\n",
    "- Complie the model as follows\n",
    "    - **model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])**\n",
    "- Fit the model as follows\n",
    "    - **model.fit(x=train_ds[0], y=train_ds[1], validation_data=(val_ds[0], val_ds[1]), epochs=5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1150/1150 [==============================] - 58s 47ms/step - loss: 0.0635 - val_loss: 0.0397\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03966, saving model to model_test.h5\n",
      "Epoch 2/10\n",
      "1150/1150 [==============================] - 57s 49ms/step - loss: 0.0336 - val_loss: 0.0344\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03966 to 0.03442, saving model to model_test.h5\n",
      "Epoch 3/10\n",
      "1150/1150 [==============================] - 59s 51ms/step - loss: 0.0312 - val_loss: 0.0338\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03442 to 0.03381, saving model to model_test.h5\n",
      "Epoch 4/10\n",
      "1150/1150 [==============================] - 56s 49ms/step - loss: 0.0300 - val_loss: 0.0346\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.03381\n",
      "Epoch 5/10\n",
      "1150/1150 [==============================] - 57s 50ms/step - loss: 0.0291 - val_loss: 0.0342\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.03381\n",
      "Epoch 6/10\n",
      "1150/1150 [==============================] - 58s 50ms/step - loss: 0.0282 - val_loss: 0.0347\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03381\n",
      "Epoch 7/10\n",
      " 947/1150 [=======================>......] - ETA: 9s - loss: 0.0271"
     ]
    }
   ],
   "source": [
    "path_checkpoint = \"model_test.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(dataset_train, epochs = epochs, validation_data=dataset_val, callbacks = [es_callback, modelckpt_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Plot the result\n",
    "- Plot a window of the data predicted together with the actual data.\n",
    "- One way:\n",
    "    - **fig, ax = plt.subplots()**\n",
    "    - **ax.plot(y[i:i+96*2,0], c='g')**\n",
    "    - **ax.plot(pred[i:i+96*2,-1,0], c='r')**\n",
    "- It will plot a window of 96 hours, where you can index with **i** (**i=150** as an example) and **y** is the real values and **pred** are the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for batch in dataset_test.take(5):\n",
    "    x, y = batch\n",
    "    \n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    y_pred = y_pred * train_std[predicted_feature] + train_mean[predicted_feature]\n",
    "    y = y * train_std[predicted_feature] + train_mean[predicted_feature]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(y[0:100], c='r', label=\"Test Data\")\n",
    "    ax.plot(y_pred[0:100], c='g', label=\"Prediction\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "for x1, y1 in dataset_test.take(5):\n",
    "    show_plot(\n",
    "        [x1[0][:, 1].numpy(), y1[0].numpy(), model.predict(x1)[0]],\n",
    "        12,\n",
    "        \"Single Step Prediction\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
